{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6f/Programming123najra.gif\" alt=\"Typing gif from Wikipedia\" width=\"500px\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spy Keypad\n",
    "\n",
    "**Part 2 for working with audio signals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**A door is encoded with a number pad (0-9). We can't see the door, but through nefarious means we have a recording of someone opening it. Quick! We need to decode this [mystery signal](https://github.com/ProjectPythia/wavelet-cookbook/blob/main/notebooks/data/mystery_signal.wav) and the order they appear to open the door!**\n",
    "\n",
    "We know that the door code is set up as:\n",
    "- A note: 0\n",
    "- B note: 1\n",
    "- C note: 2\n",
    "- D note: 3\n",
    "- E note: 4\n",
    "- F note: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Matplotlib](https://foundations.projectpythia.org/core/matplotlib/matplotlib-basics.html) | Necessary | Used to plot data |\n",
    "| [Intro to Pandas](https://foundations.projectpythia.org/core/pandas/pandas.html) | Necessary | Used to read in and organize data (in particular dataframes) |\n",
    "| [Intro to Numpy](https://foundations.projectpythia.org/core/numpy/numpy-basics.html)| Necessary | Used to work with large arrays |\n",
    "| [Intro to SciPy](https://docs.scipy.org/doc/scipy-1.13.1/tutorial/fft.html) | Helpful | Used to work with .wav files and built-in Fast Fourier Transform |\n",
    "\n",
    "- **Time to learn**: 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          # working with arrays\n",
    "import pandas as pd                         # working with dataframes\n",
    "from scipy.io import wavfile                # loading in wav files\n",
    "import matplotlib.pyplot as plt             # plot data\n",
    "from scipy.fftpack import fft, fftfreq      # working with Fourier Transforms\n",
    "\n",
    "import pywt                                 # PyWavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract audio .wav file\n",
    "As when working with the \"Jingle Bells\" song file, any .wav input file contains information about the amplitude at every point in the file. The frequency of the note will determine which chord each part of the piece represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate, signalData = wavfile.read('../data/mystery_signal.wav')\n",
    "\n",
    "duration = len(signalData) / sampleRate\n",
    "time = np.arange(0, duration, 1/sampleRate) \n",
    "\n",
    "print(f\"Sample Rate: {sampleRate}\")\n",
    "print(f\"duration = {duration} seconds\")\n",
    "print(f\"Total length in time steps = {len(time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Give the Data a Look!\n",
    "\n",
    "It is always good practice to view the data that we have collected. First, let's organize the data into a `pandas` dataframe to organize the amplitude and time stamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df = pd.DataFrame({'time (seconds)': time, 'amplitude': signalData})\n",
    "signal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Small Sample of the .wav File\n",
    "\n",
    "Plot a small subsample of the .wav to visualize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "fig = plt.plot(signal_df[\"time (seconds)\"], signal_df[\"amplitude\"])\n",
    "plt.title(\"Subsample of Mystery Audio File\")\n",
    "ax.set_xlim(signal_df[\"time (seconds)\"][2000], signal_df[\"time (seconds)\"][4000])\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Analysis: Power Spectrum\n",
    "\n",
    "The power spectrum plots the real component of the complex number returns from wavelet coefficients. This will return information about the frequency and time that we need to use to determine which notes are used in what order for the keypad.\n",
    "\n",
    "For the purpose of this example, we will use the Morlet mother wavelet. Morlet is one type of mother wavelet useful for working with audio signals and is a good general wavelet to start with when analyzing frequencies of a signal.\n",
    "\n",
    "However, choosing which wavelet to use is an important step as different wavelets will be sensitive to different features in time-series data.\n",
    "\n",
    "[To learn more!](https://www.mathworks.com/help/wavelet/gs/choose-a-wavelet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_mother = \"morl\" # morlet mother wavelet\n",
    "\n",
    "# scale determines how squished or stretched a wavelet is\n",
    "scales = np.arange(1, 40)\n",
    "wavelet_coeffs, freqs = pywt.cwt(signalData, scales, wavelet = wavelet_mother)\n",
    "\n",
    "# Shape of wavelet transform\n",
    "print(f\"size {wavelet_coeffs.shape} with {wavelet_coeffs.shape[0]} scales and {wavelet_coeffs.shape[1]} time steps\")\n",
    "print(f\"x-axis is: {wavelet_coeffs.shape[1]}\")\n",
    "print(f\"y-axis is: {wavelet_coeffs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Scalogram\n",
    "\n",
    "We will be plotting the wavelet as a scalogram, where the presence of a strong match to a specific frequency will be a darker color. This will create distinct bands of a dark color where a specific frequency is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "data = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Scale Sensitivity\")\n",
    "plt.imshow(data, \n",
    "           vmax=(data).max(), vmin=(data).min(),\n",
    "           cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behold! Distinct Bands of Frequencies!\n",
    "Each distinct band represents a note. So, we can see that the data at the beginning and at the end is random noise, with no distinct frequency. But at 1 second, a distinct note that lasts for 1 second, followed by three additional distinct bands. We now know the code is four numbers long. But now we need to determine what the numbers are and what their order is. Let's see where the possible note frequencies we have by overlaying the frequencies of each note onto the wavelet scalogram.\n",
    "\n",
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Important Note</p>\n",
    "   To convert Hz frequency to a <code>scale = hz *.0001</code> (where 0.01 is 100 Hz sampling) then apply <code>frequency2scale</code> PyWavelets function\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Overlay frequency of notes as dotted lines\n",
    "sample_rate = 1/sampleRate\n",
    "a_freq = pywt.frequency2scale(wavelet_mother, 440*sample_rate)\n",
    "plt.axhline(y=a_freq, color='lightpink', linestyle='--', label='A') # A note: 440 hz\n",
    "b_freq = pywt.frequency2scale(wavelet_mother, 494*sample_rate)\n",
    "plt.axhline(y=b_freq, color=\"blue\", linestyle='--', label='B')      # B Note: 494 hz\n",
    "c_freq = pywt.frequency2scale(wavelet_mother, 261*sample_rate)\n",
    "plt.axhline(y=c_freq, color='lightblue', linestyle='--', label='C') # C Note: 261 hz\n",
    "d_freq = pywt.frequency2scale(wavelet_mother, 293*sample_rate)\n",
    "plt.axhline(y=d_freq, color='green', linestyle='--', label='D')     # D Note: 293 hz\n",
    "e_freq = pywt.frequency2scale(wavelet_mother, 330*sample_rate)\n",
    "plt.axhline(y=e_freq, color='orange', linestyle='--', label='E')    # E Note: 330 hz\n",
    "f_freq = pywt.frequency2scale(wavelet_mother, 350*sample_rate)\n",
    "plt.axhline(y=f_freq, color='grey', linestyle='--', label='F')      # F Note: 350 hz\n",
    "g_freq = pywt.frequency2scale(wavelet_mother, 392*sample_rate)\n",
    "plt.axhline(y=g_freq, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n",
    "\n",
    "# Plot Power scalogram\n",
    "power = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\n",
    "plt.title(\"Note Frequency as Scale\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Scale Sensitivity\")\n",
    "plt.imshow(power, \n",
    "           vmax=(power).max(), vmin=(power).min(),\n",
    "           cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But Which Match Best?\n",
    "\n",
    "We are looking for a note frequency that best lines up with the darkest part of each band. The first and the last band seem like the same note, but is it closer to an A note or a B note?\n",
    "\n",
    "Let's see if we can use Fourier Transform to get a smaller range of notes to chose from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_transform = abs(fft(signalData))\n",
    "freqs = fftfreq(len(fourier_transform), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.plot(freqs, fourier_transform)\n",
    "ax.set_xlim(left=200, right=500) \n",
    "plt.axvline(x=440, color=\"lightpink\", label=\"A\",alpha=0.5) # A note: 440 hz\n",
    "plt.axvline(x=494, color=\"blue\", label=\"B\",alpha=0.5)      # B Note: 494 hz\n",
    "plt.axvline(x=261, color=\"lightblue\", label=\"C\",alpha=0.5) # C Note: 261 hz\n",
    "plt.axvline(x=293, color=\"green\", label=\"D\",alpha=0.5)     # D Note: 293 hz\n",
    "plt.axvline(x=330, color=\"orange\", label=\"E\",alpha=0.5)    # E Note: 330 hz\n",
    "plt.axvline(x=350, color=\"grey\", label=\"F\",alpha=0.5)      # F Note: 350 hz\n",
    "plt.axvline(x=392, color=\"purple\", label=\"G\",alpha=0.5)    # G Note: 392 hz\n",
    "plt.title(\"Signal Frequency Prevalence (FFT)\")\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfect, There are Three Notes!\n",
    "\n",
    "Three notes stand out, and one note is used about twice as much as the other two: A, B, F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Overlay frequency of notes as dotted lines\n",
    "sample_rate = 1/sampleRate\n",
    "a_freq = pywt.frequency2scale(wavelet_mother, 440*sample_rate)\n",
    "plt.axhline(y=a_freq, color='cyan', linestyle='--', label='A')\n",
    "b_freq = pywt.frequency2scale(wavelet_mother, 494*sample_rate)\n",
    "plt.axhline(y=b_freq, color=\"green\", linestyle='--', label='B')\n",
    "f_freq = pywt.frequency2scale(wavelet_mother, 350*sample_rate)\n",
    "plt.axhline(y=f_freq, color='grey', linestyle='--', label='F')\n",
    "\n",
    "# Plot Power scalogram\n",
    "power = np.log2(np.square(abs(wavelet_coeffs))) # compare the magnitude\n",
    "plt.title(\"Note Frequency as Scale\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Scale Sensitivity\")\n",
    "plt.imshow(power, \n",
    "           vmax=(power).max(), vmin=(power).min(),\n",
    "           cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Notes Played Over Six Seconds\n",
    "\n",
    "We have the keypad solution! The three notes are played (sometimes repeated) over the course of the six seconds.\n",
    "\n",
    "### A, B, F, A\n",
    "\n",
    "\n",
    "From our original problem, we know that the door code is set up as:\n",
    "- A note: 0\n",
    "- B note: 1\n",
    "- C note: 2\n",
    "- D note: 3\n",
    "- E note: 4\n",
    "- F note: 5\n",
    "\n",
    "The solution to the door password is:\n",
    "\n",
    "### 0, 1, 5, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Now we've had a chance to work with unknown input values, but within an expected range. Different time-series data will have different ranges of expected frequencies, and with Fourier Transform and wavelet analysis it is possible to pull out such relevant data.\n",
    "\n",
    "### What's next?\n",
    "\n",
    "**Up next: apply wavelets transform and work with weather data!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
