{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/68/Animation_portail_musique.gif\" alt=\"Piano gif from Wikipedia\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyWavelets and Jingle Bells\n",
    "\n",
    "**Part 1 for working with audio signals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will generate a wavelet scalogram to determine the order of notes in a short .wav file. You'll learn how to generate a Wavelet Power spectrum graph\n",
    "\n",
    "1. Prerequisites\n",
    "2. Background\n",
    "3. PyWavelets Overview\n",
    "4. Wavelet Power Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Matplotlib](https://foundations.projectpythia.org/core/matplotlib/matplotlib-basics.html) | Necessary | Used to plot data |\n",
    "| [Intro to Pandas](https://foundations.projectpythia.org/core/pandas/pandas.html) | Necessary | Used to read in and organize data (in particular dataframes) |\n",
    "| [Intro to Numpy](https://foundations.projectpythia.org/core/numpy/numpy-basics.html)| Necessary | Used to work with large arrays |\n",
    "| [Intro to SciPy](https://docs.scipy.org/doc/scipy-1.13.1/tutorial/fft.html) | Helpful | Used to work with .wav files and built-in Fast Fourier Transform |\n",
    "\n",
    "- **Time to learn**: 20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Wavelet analysis is accomplished in Python via external package. [PyWavelets](https://pywavelets.readthedocs.io/en/latest/ref/cwt.html#pywt.cwt) is an open source Python package for wavelet analysis\n",
    "\n",
    "Either with pip install:\n",
    "```\n",
    "pip install PyWavelets\n",
    "```\n",
    "\n",
    "Or with conda\n",
    "```\n",
    "conda install pywavelets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                          # working with arrays\n",
    "import pandas as pd                         # working with dataframes\n",
    "from scipy.io import wavfile                # loading in wav files\n",
    "import matplotlib.pyplot as plt             # plot data\n",
    "from scipy.fftpack import fft, fftfreq      # working with Fourier Transforms\n",
    "\n",
    "import pywt                                 # PyWavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyWavelets Overview\n",
    "\n",
    "PyWavelets returns both the coefficients and frequency information for wavelets from the input data\n",
    "\n",
    "```\n",
    "coeffs, frequencies = pywt.cwt(data, scales, wavelet, sampling_period)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Values\n",
    "The [Continuous Wavelet Transform (CWT)](https://pywavelets.readthedocs.io/en/latest/ref/cwt.html) in PyWavelets accepts multiple input values:\n",
    "\n",
    "Required:\n",
    "- data: input data (as an array)\n",
    "- wavelet: name of the Mother wavelet\n",
    "- scales: collection of the scales to use will determine the range which the wavelet will be stretched or squished\n",
    "\n",
    "Optional:\n",
    "- sampling_period: sampling period for frequencies output. Scales are not scaled by the period (and coefficients are independent of the sampling_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Values\n",
    "The continuous wavelet transforms in PyWavelets returns two values:\n",
    "\n",
    "- coefficients: collection of complex number outputs for wavelet coefficients\n",
    "- frequencies: collection of frequencies (if the sampling period are in seconds then frequencies are in hertz otherwise a sampling period of 1 is assumed)\n",
    "\n",
    "The final size of coefficients depends on the length of the input data and the length of the given scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Scale\n",
    "#### Scales vs. Frequency\n",
    "\n",
    "The range of scales are a combination of the smallest scale (s0), spacing between discrete scales (dj), and the maximum scale (jtot). \n",
    "\n",
    "For the purpose of this exercise, the musical range of frequencies range from 261 - 494 Hz.\n",
    "\n",
    "| Note   | Freq   |\n",
    "|--------|--------|\n",
    "| A note | 440 hz |\n",
    "| B note | 494 hz |\n",
    "| C note | 261 hz |\n",
    "| D note | 293 hz |\n",
    "| E note | 330 hz |\n",
    "| F note | 350 hz |\n",
    "| G note | 392 hz |\n",
    "\n",
    "\n",
    "_Note: Musical note frequencies can vary, these frequencies are taken from [here](https://mixbutton.com/mixing-articles/music-note-to-frequency-chart/)_\n",
    "\n",
    "It is good practice to include a range greater than precisely needed. This will make the bands for each frequency in the wavelets clearer.\n",
    "\n",
    "Scales will change the shape of the wavelet to have it match a specific frequency. For example, scalings from 1 to 40 represent a frequency range from 8125 - 208.33 Hz.\n",
    "\n",
    "```\n",
    "sample_rate, signal_data = wavfile.read('jingle_bells.wav')\n",
    "scales = np.arange(1, 40)\n",
    "wavelet_coeffs, freqs = pywt.cwt(signal_data, scales, wavelet = \"morl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract audio .wav file\n",
    "The .wav input file contains information about the amplitude at every time step (in seconds) in the file. The frequency will determine which note each part of the piece represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate, signalData = wavfile.read(\"../data/jingle_bells.wav\")\n",
    "\n",
    "duration = len(signalData) / sampleRate\n",
    "time = np.arange(0, duration, 1/sampleRate) \n",
    "\n",
    "print(f\"Sample Rate: {sampleRate}\")\n",
    "print(f\"duration = {duration} seconds\")\n",
    "print(f\"Total Length in time steps = {len(time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Give the Data a Look!\n",
    "\n",
    "It is always good practice to view the data that we have collected. First, let's organize the data into a `pandas` dataframe to organize the amplitude and time stamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df = pd.DataFrame({'time (seconds)': time, 'amplitude': signalData})\n",
    "signal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Small Sample of the .wav File\n",
    "\n",
    "Plot a small subsample of the .wav to visualize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "fig = plt.plot(signal_df[\"time (seconds)\"], signal_df[\"amplitude\"])\n",
    "plt.title(\"Subsample of \\\"Jingle Bells\\\" Audio File\")\n",
    "ax.set_xlim(signal_df[\"time (seconds)\"][2000], signal_df[\"time (seconds)\"][3000])\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wavelet_coeffs` is a complex number with a real and an imaginary part (1 + 2i). The power spectrum plots the real component of the complex number. The real component represents the magnitude of the wavelet coefficient displayed as the absolute value of the coefficients squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_mother = \"morl\" # morlet mother wavelet\n",
    "\n",
    "# scale determines how squished or stretched a wavelet is\n",
    "scales = np.arange(1, 40)\n",
    "wavelet_coeffs, freqs = pywt.cwt(signalData, scales, wavelet = wavelet_mother)\n",
    "\n",
    "# Shape of wavelet transform\n",
    "print(f\"size {wavelet_coeffs.shape} with {wavelet_coeffs.shape[0]} scales and {wavelet_coeffs.shape[1]} time steps\")\n",
    "print(f\"x-axis be default is: {wavelet_coeffs.shape[1]}\")\n",
    "print(f\"y-axis be default is: {wavelet_coeffs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Choosing the Right Scales\n",
    "\n",
    "`freqs` is normalized frequencies, so it needs to be multiplied by this sampling frequency to turn it back into frequencies which means that you need to multiply them by your sampling frequency (500Hz) to turn them into actual frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_mother = \"morl\" # morlet mother wavelet\n",
    "\n",
    "# scale determines how squished or stretched a wavelet is\n",
    "scales = np.arange(1, 40)\n",
    "wavelet_coeffs, freqs = pywt.cwt(signalData, scales, wavelet = wavelet_mother)\n",
    "\n",
    "plt.axhline(y=440, color='lightpink', linestyle='--', label='A') # A note: 440 hz\n",
    "plt.axhline(y=494, color=\"lightblue\", linestyle='--', label='B') # B Note: 494 hz\n",
    "plt.axhline(y=261, color='red', linestyle='--', label='C')       # C Note: 261 hz\n",
    "plt.axhline(y=293, color='green', linestyle='--', label='D')     # D Note: 293 hz\n",
    "plt.axhline(y=330, color='orange', linestyle='--', label='E')    # E Note: 330 hz\n",
    "plt.axhline(y=350, color='grey', linestyle='--', label='F')      # F Note: 350 hz\n",
    "plt.axhline(y=392, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n",
    "\n",
    "plt.xlabel(\"Scale\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "print(f\"Frequency in Hz:\\n{freqs*sampleRate}\")\n",
    "plt.plot(freqs*sampleRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scalogram\n",
    "\n",
    "The scalogram will visually display the strength of the frequency at a particular time interval. A stronger signal in red represents a wavelet that strongly matches a specific frequency in that range, while blue represents where the wavelet has a weaker match to a specific frequency. The best match for a note will be found where the signal is strongest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "data = np.log2(np.square(abs(wavelet_coeffs))) # compare the magnitude\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Scale Sensitivity\")\n",
    "plt.imshow(data, \n",
    "           vmax=(data).max(), vmin=(data).min(),\n",
    "           cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay Possible Frequencies\n",
    "\n",
    "To overlay these frequencies with the wavelet scalogram:\n",
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Important Note</p>\n",
    "   To convert HZ frequency to a <code>scale = hz *.0001</code> (where 0.01 is 100 Hz sampling) then apply <code>frequency2scale()</code> PyWavelets function\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Overlay frequency of notes as dotted lines\n",
    "sample_rate = 1/sampleRate\n",
    "a_freq = pywt.frequency2scale(wavelet_mother, 440*sample_rate)\n",
    "plt.axhline(y=a_freq, color='lightpink', linestyle='--', label='A') # A note: 440 hz\n",
    "b_freq = pywt.frequency2scale(wavelet_mother, 494*sample_rate)\n",
    "plt.axhline(y=b_freq, color=\"lightblue\", linestyle='--', label='B') # B Note: 494 hz\n",
    "c_freq = pywt.frequency2scale(wavelet_mother, 261*sample_rate)\n",
    "plt.axhline(y=c_freq, color='red', linestyle='--', label='C')       # C Note: 261 hz\n",
    "d_freq = pywt.frequency2scale(wavelet_mother, 293*sample_rate)\n",
    "plt.axhline(y=d_freq, color='green', linestyle='--', label='D')     # D Note: 293 hz\n",
    "e_freq = pywt.frequency2scale(wavelet_mother, 330*sample_rate)\n",
    "plt.axhline(y=e_freq, color='orange', linestyle='--', label='E')    # E Note: 330 hz\n",
    "f_freq = pywt.frequency2scale(wavelet_mother, 350*sample_rate)\n",
    "plt.axhline(y=f_freq, color='grey', linestyle='--', label='F')      # F Note: 350 hz\n",
    "g_freq = pywt.frequency2scale(wavelet_mother, 392*sample_rate)\n",
    "plt.axhline(y=g_freq, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n",
    "\n",
    "# Plot Power scalogram\n",
    "power = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\n",
    "plt.title(\"Note Frequency as Scale\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Scale Sensitivity\")\n",
    "plt.imshow(power, \n",
    "           vmax=(power).max(), vmin=(power).min(),\n",
    "           cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Which Frequencies to Overlay\n",
    "\n",
    "For this example, we know that the input data is \"Jingle Bells\" so we know which notes are going to be used.\n",
    "\n",
    "```\n",
    "\"Jingle Bells, Jingle Bells, Jingle All the Way\" as EEE EEE EGCDE\n",
    "```\n",
    "\n",
    "However, let's imagine that we aren't sure. Wavelets gain information about _when_ a frequency occurs, but at a lower resolution to an exact frequency. To determine which notes are a best fit, you can make use of FFT to determinine which notes to include. Without FFT, the larger possible ranges of frequency can make it possible to confuse nearby notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_transform = abs(fft(signalData))\n",
    "freqs = fftfreq(len(fourier_transform), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.plot(freqs, fourier_transform)\n",
    "ax.set_xlim(left=200, right=500) \n",
    "plt.axvline(x=261, color=\"red\", label=\"C\",alpha=0.5)    # C Note: 261 hz\n",
    "plt.axvline(x=293, color=\"green\", label=\"D\",alpha=0.5)  # D Note: 293 hz\n",
    "plt.axvline(x=330, color=\"orange\", label=\"E\",alpha=0.5) # E Note: 330 hz\n",
    "plt.axvline(x=391, color=\"purple\", label=\"G\",alpha=0.5) # G Note: 391 hz\n",
    "plt.title(\"Signal Frequency Prevalence (FFT)\")\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay Frequency of Notes\n",
    "Using FFT we can now say that there are four clear frequencies that are associated with four notes for CDEG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transform Predicts Four Notes\n",
    "\n",
    "FFT predicts an output with four notes: \n",
    "\n",
    "```\n",
    "C, D, E, G\n",
    "```\n",
    "Let's plot the notes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Overlay frequency of notes as dotted lines\n",
    "sample_rate = 1/sampleRate\n",
    "c_freq = pywt.frequency2scale(wavelet_mother, 261*sample_rate)\n",
    "plt.axhline(y=c_freq, color='red', linestyle='--', label='C')       # C Note: 261 hz\n",
    "d_freq = pywt.frequency2scale(wavelet_mother, 293*sample_rate)\n",
    "plt.axhline(y=d_freq, color='green', linestyle='--', label='D')     # D Note: 293 hz\n",
    "e_freq = pywt.frequency2scale(wavelet_mother, 330*sample_rate)\n",
    "plt.axhline(y=e_freq, color='orange', linestyle='--', label='E')    # E Note: 330 hz\n",
    "g_freq = pywt.frequency2scale(wavelet_mother, 392*sample_rate)\n",
    "plt.axhline(y=g_freq, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n",
    "\n",
    "# Plot Power scalogram\n",
    "power = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\n",
    "plt.title(\"Note Frequency as Scale\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Scale Sensitivity\")\n",
    "plt.imshow(power, \n",
    "           vmax=(power).max(), vmin=(power).min(),\n",
    "           cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Notes!\n",
    "\n",
    "The darkest color correlates with the frequency at each time stamp. Rather than appearing as distinct peaks like a Fourier Transform, wavelets return a gradient of frequencies. This is the loss in precision due to Heisenberg's Uncertainty Principle. While the frequencies can still be determined, there is some level of uncertainty in the exact frequencies. This is where combining wavelets with a Fourier Transform can be useful. We now know that this piece has four notes `CDEG`. The vertical bands represent where the note ends before the next note begins. This piece of music has a deliberate start and stop so this band will not always be as obvious in other pieces of music.\n",
    "\n",
    "We can read this wavelet analysis by finding what note corresponds with the darkest band. \n",
    "\n",
    "We should now have the order of the notes, read from left to right:\n",
    "\n",
    "### EEE EEE EGCDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Wavelets can report on both the frequency and time a frequency occurs. However, due to Heisenberg's Uncertainty Principle, by gaining resolution on time, some resolution on frequency is lost. It can be helpful to incorporate both a Fourier Transform and a Wavelet analysis to a signal to help determine the possible ranges of expected frequencies. `PyWavelets` is a free open-source package for wavelets in Python.\n",
    "\n",
    "### What's next?\n",
    "\n",
    "**Up next: apply wavelets transform to determine the frequency _and_ order of an unknown input!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
